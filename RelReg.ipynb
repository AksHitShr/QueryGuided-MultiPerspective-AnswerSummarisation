{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:06.268922Z",
     "iopub.status.busy": "2024-11-18T18:29:06.268194Z",
     "iopub.status.idle": "2024-11-18T18:29:18.439686Z",
     "shell.execute_reply": "2024-11-18T18:29:18.438481Z",
     "shell.execute_reply.started": "2024-11-18T18:29:06.268891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate rouge-score > /dev/null 2>&1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:18.442363Z",
     "iopub.status.busy": "2024-11-18T18:29:18.442106Z",
     "iopub.status.idle": "2024-11-18T18:29:36.351410Z",
     "shell.execute_reply": "2024-11-18T18:29:36.350719Z",
     "shell.execute_reply.started": "2024-11-18T18:29:18.442338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import evaluate\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:36.352875Z",
     "iopub.status.busy": "2024-11-18T18:29:36.352332Z",
     "iopub.status.idle": "2024-11-18T18:29:39.114773Z",
     "shell.execute_reply": "2024-11-18T18:29:39.113838Z",
     "shell.execute_reply.started": "2024-11-18T18:29:36.352847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9682b024f14bb4816c2f2830d4ca67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge=evaluate.load(\"rouge\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:39.116737Z",
     "iopub.status.busy": "2024-11-18T18:29:39.116450Z",
     "iopub.status.idle": "2024-11-18T18:29:46.436045Z",
     "shell.execute_reply": "2024-11-18T18:29:46.435134Z",
     "shell.execute_reply.started": "2024-11-18T18:29:39.116712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9a52c3477e4a5ab88ef5208a0b7caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f60fc32a414430dbb0b6d3273b03c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl:   0%|          | 0.00/24.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2365882a0434ee0baf4ca39116827a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.jsonl:   0%|          | 0.00/4.43M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69feba912fd2406695eef69c4a5eb957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl:   0%|          | 0.00/8.76M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31069913f2c348c1bb4205a597899460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2783 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad373c9f5b644088ac7295a5d250e476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661fb4971e05480ba478288ebf5f43b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answersumm = load_dataset(\"alexfabbri/answersumm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:45:30.382540Z",
     "iopub.status.busy": "2024-11-16T08:45:30.382209Z",
     "iopub.status.idle": "2024-11-16T08:45:33.951494Z",
     "shell.execute_reply": "2024-11-16T08:45:33.950671Z",
     "shell.execute_reply.started": "2024-11-16T08:45:30.382505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data=answersumm['train']\n",
    "query_dataset=[]\n",
    "ref_summ_dataset=[]\n",
    "sentence_dataset=[]\n",
    "for sample in train_data:\n",
    "    ref_summ=sample['summaries'][0][1]\n",
    "    query=sample['question']['question']\n",
    "    for ans in sample['answers']:\n",
    "        for sent in ans['sents']:\n",
    "            sentence_dataset.append(sent['text'])\n",
    "            ref_summ_dataset.append(ref_summ)\n",
    "            query_dataset.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:46.437318Z",
     "iopub.status.busy": "2024-11-18T18:29:46.437063Z",
     "iopub.status.idle": "2024-11-18T18:29:46.441573Z",
     "shell.execute_reply": "2024-11-18T18:29:46.440634Z",
     "shell.execute_reply.started": "2024-11-18T18:29:46.437293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_rouge_score(sent,ref_summary):\n",
    "    results=rouge.compute(predictions=[sent], references=[ref_summary])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:46.442931Z",
     "iopub.status.busy": "2024-11-18T18:29:46.442677Z",
     "iopub.status.idle": "2024-11-18T18:29:46.455970Z",
     "shell.execute_reply": "2024-11-18T18:29:46.455053Z",
     "shell.execute_reply.started": "2024-11-18T18:29:46.442906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RelRegDataset(Dataset):\n",
    "    def __init__(self, tokenizer, max_len, queries, sentences, summaries):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.queries=queries\n",
    "        self.summaries=summaries\n",
    "        self.sentences=sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        query = self.queries[idx]\n",
    "        summary = self.summaries[idx]\n",
    "        \n",
    "        target = compute_rouge_score(sentence,summary)\n",
    "        \n",
    "        inputs = self.tokenizer(query, sentence, \n",
    "                                max_length=self.max_len, \n",
    "                                padding=\"max_length\", \n",
    "                                truncation=True, \n",
    "                                return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'token_type_ids': inputs['token_type_ids'].squeeze(0),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:46.457252Z",
     "iopub.status.busy": "2024-11-18T18:29:46.456990Z",
     "iopub.status.idle": "2024-11-18T18:29:46.466761Z",
     "shell.execute_reply": "2024-11-18T18:29:46.465953Z",
     "shell.execute_reply.started": "2024-11-18T18:29:46.457227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RelRegModel(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-uncased\"):\n",
    "        super(RelRegModel, self).__init__()\n",
    "        self.encoder = BertModel.from_pretrained(model_name)\n",
    "        self.regressor = nn.Linear(self.encoder.config.hidden_size, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.encoder(input_ids=input_ids, \n",
    "                               attention_mask=attention_mask, \n",
    "                               token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        score = self.regressor(pooled_output)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:46.467981Z",
     "iopub.status.busy": "2024-11-18T18:29:46.467674Z",
     "iopub.status.idle": "2024-11-18T18:29:49.045944Z",
     "shell.execute_reply": "2024-11-18T18:29:49.045222Z",
     "shell.execute_reply.started": "2024-11-18T18:29:46.467955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1235fb17c51146e09f1fe8995ac9a292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac62c21c6c9d4f5eab7d47c12f335353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1e521b5fdd446fa099c30120b2a329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392003aa535c49788f0c5e7c51504b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=RelRegModel()\n",
    "model=model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.MSELoss()\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:45:37.913261Z",
     "iopub.status.busy": "2024-11-16T08:45:37.912952Z",
     "iopub.status.idle": "2024-11-16T08:45:37.918783Z",
     "shell.execute_reply": "2024-11-16T08:45:37.917512Z",
     "shell.execute_reply.started": "2024-11-16T08:45:37.913228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset=RelRegDataset(tokenizer,512,query_dataset[:3200],sentence_dataset[:3200],ref_summ_dataset[:3200])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T08:45:37.920302Z",
     "iopub.status.busy": "2024-11-16T08:45:37.920009Z",
     "iopub.status.idle": "2024-11-16T09:53:16.001681Z",
     "shell.execute_reply": "2024-11-16T09:53:16.000678Z",
     "shell.execute_reply.started": "2024-11-16T08:45:37.920269Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Loss: 0.0190\n",
      "\n",
      "\n",
      "Epoch 2, Loss: 0.0029\n",
      "\n",
      "\n",
      "Epoch 3, Loss: 0.0027\n",
      "\n",
      "\n",
      "Epoch 4, Loss: 0.0025\n",
      "\n",
      "\n",
      "Epoch 5, Loss: 0.0024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(1,epochs+1):\n",
    "    total_loss=0\n",
    "    for i,batch in enumerate(train_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = criterion(outputs.squeeze(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%100==0:\n",
    "            print(f\"Epoch: {epoch}, Batch: {i+1} | {len(train_dataloader)}, Loss: {loss.item()}\")\n",
    "        total_loss += loss.item()\n",
    "    train_loss=total_loss/len(train_dataloader)\n",
    "    print()\n",
    "    print(f\"Epoch {epoch}, Loss: {train_loss:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T09:53:16.003154Z",
     "iopub.status.busy": "2024-11-16T09:53:16.002853Z",
     "iopub.status.idle": "2024-11-16T09:53:16.631169Z",
     "shell.execute_reply": "2024-11-16T09:53:16.630360Z",
     "shell.execute_reply.started": "2024-11-16T09:53:16.003121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"RelReg2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:49.047425Z",
     "iopub.status.busy": "2024-11-18T18:29:49.047060Z",
     "iopub.status.idle": "2024-11-18T18:29:53.639574Z",
     "shell.execute_reply": "2024-11-18T18:29:53.638763Z",
     "shell.execute_reply.started": "2024-11-18T18:29:49.047367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/2089666756.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model=torch.load('../input/anlp-relreg/RelReg.pth')\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('../input/anlp-relreg/RelReg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:53.642445Z",
     "iopub.status.busy": "2024-11-18T18:29:53.642066Z",
     "iopub.status.idle": "2024-11-18T18:29:53.653437Z",
     "shell.execute_reply": "2024-11-18T18:29:53.652757Z",
     "shell.execute_reply.started": "2024-11-18T18:29:53.642381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:29:59.252924Z",
     "iopub.status.busy": "2024-11-18T18:29:59.252073Z",
     "iopub.status.idle": "2024-11-18T18:30:12.730258Z",
     "shell.execute_reply": "2024-11-18T18:30:12.729539Z",
     "shell.execute_reply.started": "2024-11-18T18:29:59.252888Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c68fa9b65949dd8a1d91fcc4bbd8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6b10df45ef40a4a8cb81c895248163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f510dbb91af4cf698305f1acd6a3e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d88c5709ff047caa3dd912a5d5dd5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8bd2a33f644591bf0ef37a7bcf387e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_30/611690884.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2=torch.load('../input/bart-ft2/BART_FT2.pth')\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer2 = BartTokenizer.from_pretrained(model_name)\n",
    "model2=torch.load('../input/bart-ft2/BART_FT2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:30:59.627927Z",
     "iopub.status.busy": "2024-11-18T18:30:59.627553Z",
     "iopub.status.idle": "2024-11-18T18:30:59.633184Z",
     "shell.execute_reply": "2024-11-18T18:30:59.632269Z",
     "shell.execute_reply.started": "2024-11-18T18:30:59.627898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(input_text):\n",
    "    inputs = tokenizer2(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model2.generate(inputs[\"input_ids\"].to(device), max_length=256, min_length=10, length_penalty=2.0, num_beams=4)\n",
    "    summary = tokenizer2.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T18:37:44.393616Z",
     "iopub.status.busy": "2024-11-18T18:37:44.393269Z",
     "iopub.status.idle": "2024-11-18T19:22:54.881020Z",
     "shell.execute_reply": "2024-11-18T19:22:54.880172Z",
     "shell.execute_reply.started": "2024-11-18T18:37:44.393589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [45:10<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "curr_data=answersumm['test']\n",
    "scores_5=[]\n",
    "scores_10=[]\n",
    "scores_15=[]\n",
    "for sample in tqdm(curr_data):\n",
    "    ref_summ=sample['summaries'][0][1]\n",
    "    query=sample['question']['question']\n",
    "    sents=[]\n",
    "    temp_scores=[]\n",
    "    for ans in sample['answers']:\n",
    "        for sent in ans['sents']:\n",
    "            inputs = tokenizer(query, sent['text'], \n",
    "                            max_length=512, \n",
    "                            padding=\"max_length\", \n",
    "                            truncation=True, \n",
    "                            return_tensors=\"pt\")\n",
    "            sents.append(sent['text'])\n",
    "            curr={\n",
    "                'input_ids': inputs['input_ids'],\n",
    "                'attention_mask': inputs['attention_mask'],\n",
    "                'token_type_ids': inputs['token_type_ids'],\n",
    "            }\n",
    "\n",
    "            input_ids = curr['input_ids'].to(device)\n",
    "            attention_mask = curr['attention_mask'].to(device)\n",
    "            token_type_ids = curr['token_type_ids'].to(device)\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            temp_scores.extend(outputs.detach().cpu().numpy().flatten().tolist())\n",
    "\n",
    "    sorted_strings = [string for _, string in sorted(zip(temp_scores, sents), reverse=True)]\n",
    "    inp_str=\"\"\n",
    "    for s in sorted_strings[:5]:\n",
    "        inp_str+=s\n",
    "    scores_5.append(compute_rouge_score(generate_summary(inp_str),ref_summ))\n",
    "    inp_str=\"\"\n",
    "    for s in sorted_strings[:10]:\n",
    "        inp_str+=s\n",
    "    scores_10.append(compute_rouge_score(generate_summary(inp_str),ref_summ))\n",
    "    inp_str=\"\"\n",
    "    for s in sorted_strings[:15]:\n",
    "        inp_str+=s\n",
    "    scores_15.append(compute_rouge_score(generate_summary(inp_str),ref_summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T19:22:55.016917Z",
     "iopub.status.busy": "2024-11-18T19:22:55.016141Z",
     "iopub.status.idle": "2024-11-18T19:22:55.025689Z",
     "shell.execute_reply": "2024-11-18T19:22:55.024853Z",
     "shell.execute_reply.started": "2024-11-18T19:22:55.016880Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.21649382091736627,\n",
       " 'rouge2': 0.05604541589640728,\n",
       " 'rougeL': 0.1628605574126917,\n",
       " 'rougeLsum': 0.16291938094210345}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "sum_dict = defaultdict(int)\n",
    "count_dict = defaultdict(int)\n",
    "for d in scores_5:\n",
    "    for key, value in d.items():\n",
    "        sum_dict[key] += value\n",
    "        count_dict[key] += 1\n",
    "average_dict = {key: sum_val / count_dict[key] for key, sum_val in sum_dict.items()}\n",
    "average_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T19:22:55.029552Z",
     "iopub.status.busy": "2024-11-18T19:22:55.029256Z",
     "iopub.status.idle": "2024-11-18T19:22:55.045907Z",
     "shell.execute_reply": "2024-11-18T19:22:55.044854Z",
     "shell.execute_reply.started": "2024-11-18T19:22:55.029525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.22813088561609593,\n",
       " 'rouge2': 0.06198112848945814,\n",
       " 'rougeL': 0.17034762589288438,\n",
       " 'rougeLsum': 0.17039890794416643}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dict = defaultdict(int)\n",
    "count_dict = defaultdict(int)\n",
    "for d in scores_10:\n",
    "    for key, value in d.items():\n",
    "        sum_dict[key] += value\n",
    "        count_dict[key] += 1\n",
    "average_dict = {key: sum_val / count_dict[key] for key, sum_val in sum_dict.items()}\n",
    "average_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T19:22:55.048333Z",
     "iopub.status.busy": "2024-11-18T19:22:55.047493Z",
     "iopub.status.idle": "2024-11-18T19:22:55.058440Z",
     "shell.execute_reply": "2024-11-18T19:22:55.057653Z",
     "shell.execute_reply.started": "2024-11-18T19:22:55.048289Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.23441618766905273,\n",
       " 'rouge2': 0.06666096561070811,\n",
       " 'rougeL': 0.1762783625629964,\n",
       " 'rougeLsum': 0.17630557344735012}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dict = defaultdict(int)\n",
    "count_dict = defaultdict(int)\n",
    "for d in scores_15:\n",
    "    for key, value in d.items():\n",
    "        sum_dict[key] += value\n",
    "        count_dict[key] += 1\n",
    "average_dict = {key: sum_val / count_dict[key] for key, sum_val in sum_dict.items()}\n",
    "average_dict"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6095580,
     "sourceId": 9918631,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6114944,
     "sourceId": 9944691,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
