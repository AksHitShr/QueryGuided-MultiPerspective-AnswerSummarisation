{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9944539,"sourceType":"datasetVersion","datasetId":6114829}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate rouge-score > /dev/null 2>&1;","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-19T20:28:31.153412Z","iopub.execute_input":"2024-11-19T20:28:31.153759Z","iopub.status.idle":"2024-11-19T20:28:42.709909Z","shell.execute_reply.started":"2024-11-19T20:28:31.153724Z","shell.execute_reply":"2024-11-19T20:28:42.708966Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\nimport torch.nn as nn\nfrom transformers import BertTokenizer, BertModel\nimport evaluate\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom torch.optim import AdamW\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:28:42.711572Z","iopub.execute_input":"2024-11-19T20:28:42.711843Z","iopub.status.idle":"2024-11-19T20:29:00.251687Z","shell.execute_reply.started":"2024-11-19T20:28:42.711817Z","shell.execute_reply":"2024-11-19T20:29:00.250891Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"rouge=evaluate.load(\"rouge\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:00.252738Z","iopub.execute_input":"2024-11-19T20:29:00.253459Z","iopub.status.idle":"2024-11-19T20:29:01.668953Z","shell.execute_reply.started":"2024-11-19T20:29:00.253419Z","shell.execute_reply":"2024-11-19T20:29:01.668074Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cc08158c7664291bb1124584e33bcc5"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def compute_rouge_score(sent,ref_summary):\n    results=rouge.compute(predictions=[sent], references=[ref_summary])\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:01.670865Z","iopub.execute_input":"2024-11-19T20:29:01.671131Z","iopub.status.idle":"2024-11-19T20:29:01.675550Z","shell.execute_reply.started":"2024-11-19T20:29:01.671106Z","shell.execute_reply":"2024-11-19T20:29:01.674675Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"answersumm = load_dataset(\"alexfabbri/answersumm\")","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:01.676426Z","iopub.execute_input":"2024-11-19T20:29:01.676672Z","iopub.status.idle":"2024-11-19T20:29:04.808940Z","shell.execute_reply.started":"2024-11-19T20:29:01.676649Z","shell.execute_reply":"2024-11-19T20:29:04.808302Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a50022c6feb48de98acae80dfd67d12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl:   0%|          | 0.00/24.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0dd2933e2145e7b97da4040f9ed479"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.jsonl:   0%|          | 0.00/4.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b97831dfdfe644db911a4418c3423b49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.jsonl:   0%|          | 0.00/8.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dbcff35012b4e1abc33404e1cd07311"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2783 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a7a6dad9194adb80e1deb400c1de73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0521e1596453445c8109ea0f11d53ed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb1cbb9927514915b1dbc0bfd55138b6"}},"metadata":{}}]},{"cell_type":"code","source":"def generate_summary(input_text):\n    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    summary_ids = model.generate(inputs[\"input_ids\"].to(device), max_length=256, min_length=10, length_penalty=2.0, num_beams=4)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:04.809862Z","iopub.execute_input":"2024-11-19T20:29:04.810120Z","iopub.status.idle":"2024-11-19T20:29:04.814994Z","shell.execute_reply.started":"2024-11-19T20:29:04.810095Z","shell.execute_reply":"2024-11-19T20:29:04.814077Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data=answersumm['train']\ninp_dataset=[]\nout_dataset=[]\nfor sample in train_data:\n    ref_summ=sample['summaries'][0][1]\n    query=sample['question']['question']\n    inp_str=\"\"\n    for ans in sample['answers']:\n        for sent in ans['sents']:\n            inp_str+=\" \"+sent['text']\n    inp_dataset.append(inp_str)\n    out_dataset.append(ref_summ)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T10:56:59.772118Z","iopub.execute_input":"2024-11-18T10:56:59.772410Z","iopub.status.idle":"2024-11-18T10:57:03.328526Z","shell.execute_reply.started":"2024-11-18T10:56:59.772380Z","shell.execute_reply":"2024-11-18T10:57:03.327714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SummarizationDataset(Dataset):\n    def __init__(self, texts, summaries, tokenizer, max_input_len=1024, max_target_len=512):\n        self.texts = texts\n        self.summaries = summaries\n        self.tokenizer = tokenizer\n        self.max_input_len = max_input_len\n        self.max_target_len = max_target_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        inputs = self.tokenizer(\n            self.texts[idx],\n            max_length=self.max_input_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        targets = self.tokenizer(\n            self.summaries[idx],\n            max_length=self.max_target_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n            \"labels\": targets[\"input_ids\"].squeeze(0),\n            \"ref_summ\": self.summaries[idx],\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:04.988221Z","iopub.execute_input":"2024-11-19T20:29:04.989055Z","iopub.status.idle":"2024-11-19T20:29:04.995081Z","shell.execute_reply.started":"2024-11-19T20:29:04.989023Z","shell.execute_reply":"2024-11-19T20:29:04.994320Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model_name = \"facebook/bart-large\"\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n# train_dataset=SummarizationDataset(inp_dataset, out_dataset, tokenizer)\n# train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n# optimizer = AdamW(model.parameters(), lr=5e-5)\n# epochs=5","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:06.064806Z","iopub.execute_input":"2024-11-19T20:29:06.065140Z","iopub.status.idle":"2024-11-19T20:29:15.287337Z","shell.execute_reply.started":"2024-11-19T20:29:06.065110Z","shell.execute_reply":"2024-11-19T20:29:15.286567Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f47f957651434d3b8dfacd04d43d54e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb95375d06f481d919064a4b7c624f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2369275fa9904438a11a5531b7af2bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86c272fbfece45618024d0ce94b10b83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0e84a3ce1de4271b048213969e08bbd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ca7964f72140bd9c09886dcec538ee"}},"metadata":{}}]},{"cell_type":"code","source":"model.train()\nfor epoch in range(epochs):\n    epoch_loss = 0\n    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels,\n        )\n        loss = outputs.loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_dataloader)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T10:57:12.059113Z","iopub.execute_input":"2024-11-18T10:57:12.059910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'BART_FT2.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Epoch 1 Loss: 1.1762466367077211","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=torch.load('../input/bart-ft/BART_FT2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-11-18T18:07:12.962667Z","iopub.execute_input":"2024-11-18T18:07:12.963013Z","iopub.status.idle":"2024-11-18T18:07:22.551279Z","shell.execute_reply.started":"2024-11-18T18:07:12.962985Z","shell.execute_reply":"2024-11-18T18:07:22.550504Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1732550558.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model=torch.load('../input/bart-ft/BART_FT2.pth')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data=answersumm['test']\ntest_inp_dataset=[]\ntest_out_dataset=[]\nfor sample in test_data:\n    ref_summ=sample['summaries'][0][1]\n    query=sample['question']['question']\n    inp_str=\"\"\n    for ans in sample['answers']:\n        for sent in ans['sents']:\n            inp_str+=\" \"+sent['text']\n    test_inp_dataset.append(inp_str)\n    test_out_dataset.append(ref_summ)\n\ntest_dataset=SummarizationDataset(test_inp_dataset,test_out_dataset,tokenizer)\ntest_dataloader=DataLoader(test_dataset,batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:29:27.427993Z","iopub.execute_input":"2024-11-19T20:29:27.428336Z","iopub.status.idle":"2024-11-19T20:29:28.195920Z","shell.execute_reply.started":"2024-11-19T20:29:27.428305Z","shell.execute_reply":"2024-11-19T20:29:28.195241Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.eval()\nscores=[]\ngen_outputs=[]\ntrue_summ=[]\nfor batch in tqdm(test_dataloader):\n    with torch.no_grad():\n        output_ids = model.generate(\n            input_ids=batch[\"input_ids\"].to(device),\n            attention_mask=batch[\"attention_mask\"].to(device),\n            max_length=256,\n            num_beams=4,\n            early_stopping=True,\n        )\n    batch_outputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output_ids]\n#     print(batch_outputs[0])\n#     print()\n#     print(batch['ref_summ'])\n    gen_outputs.extend(batch_outputs)\n    true_summ.extend(batch['ref_summ'])\nfor a,b in tqdm(zip(gen_outputs,true_summ)):\n    scores.append(compute_rouge_score(a,b))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-19T20:29:40.078188Z","iopub.execute_input":"2024-11-19T20:29:40.078553Z","iopub.status.idle":"2024-11-19T21:07:15.975320Z","shell.execute_reply.started":"2024-11-19T20:29:40.078516Z","shell.execute_reply":"2024-11-19T21:07:15.974421Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 250/250 [35:11<00:00,  8.45s/it]\n1000it [02:24,  6.93it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"arr=[]\nfor x in scores:\n    arr.append(x['rouge1'])\nnp.average(arr)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T21:07:15.976816Z","iopub.execute_input":"2024-11-19T21:07:15.977091Z","iopub.status.idle":"2024-11-19T21:07:15.983166Z","shell.execute_reply.started":"2024-11-19T21:07:15.977064Z","shell.execute_reply":"2024-11-19T21:07:15.982420Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.16097304840136925"},"metadata":{}}]},{"cell_type":"code","source":"arr=[]\nfor x in scores:\n    arr.append(x['rouge2'])\nnp.average(arr)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T21:07:15.984417Z","iopub.execute_input":"2024-11-19T21:07:15.984744Z","iopub.status.idle":"2024-11-19T21:07:16.003973Z","shell.execute_reply.started":"2024-11-19T21:07:15.984709Z","shell.execute_reply":"2024-11-19T21:07:16.003147Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.04846841487182404"},"metadata":{}}]},{"cell_type":"code","source":"arr=[]\nfor x in scores:\n    arr.append(x['rougeL'])\nnp.average(arr)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T21:07:16.005627Z","iopub.execute_input":"2024-11-19T21:07:16.005878Z","iopub.status.idle":"2024-11-19T21:07:16.017477Z","shell.execute_reply.started":"2024-11-19T21:07:16.005855Z","shell.execute_reply":"2024-11-19T21:07:16.016637Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.10059751991493326"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}