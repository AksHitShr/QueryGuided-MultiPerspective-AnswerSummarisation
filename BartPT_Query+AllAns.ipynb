{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9944539,"sourceType":"datasetVersion","datasetId":6114829}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate rouge-score > /dev/null 2>&1;","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-19T20:52:41.119407Z","iopub.execute_input":"2024-11-19T20:52:41.119760Z","iopub.status.idle":"2024-11-19T20:52:52.308063Z","shell.execute_reply.started":"2024-11-19T20:52:41.119727Z","shell.execute_reply":"2024-11-19T20:52:52.307081Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\nimport torch.nn as nn\nfrom transformers import BertTokenizer, BertModel\nimport evaluate\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom transformers import BartForConditionalGeneration, BartTokenizer\nfrom torch.optim import AdamW\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:52:52.309655Z","iopub.execute_input":"2024-11-19T20:52:52.309894Z","iopub.status.idle":"2024-11-19T20:53:09.233169Z","shell.execute_reply.started":"2024-11-19T20:52:52.309870Z","shell.execute_reply":"2024-11-19T20:53:09.232250Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"rouge=evaluate.load(\"rouge\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:09.234325Z","iopub.execute_input":"2024-11-19T20:53:09.235033Z","iopub.status.idle":"2024-11-19T20:53:10.584420Z","shell.execute_reply.started":"2024-11-19T20:53:09.234991Z","shell.execute_reply":"2024-11-19T20:53:10.583571Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75ba6e0a44024a53a09c2c60f40d3390"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def compute_rouge_score(sent,ref_summary):\n    results=rouge.compute(predictions=[sent], references=[ref_summary])\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:10.586140Z","iopub.execute_input":"2024-11-19T20:53:10.586420Z","iopub.status.idle":"2024-11-19T20:53:10.590919Z","shell.execute_reply.started":"2024-11-19T20:53:10.586395Z","shell.execute_reply":"2024-11-19T20:53:10.590088Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"answersumm = load_dataset(\"alexfabbri/answersumm\")","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:10.591767Z","iopub.execute_input":"2024-11-19T20:53:10.592027Z","iopub.status.idle":"2024-11-19T20:53:13.281518Z","shell.execute_reply.started":"2024-11-19T20:53:10.592004Z","shell.execute_reply":"2024-11-19T20:53:13.280814Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0dd419b912542f9a518c14805f17414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl:   0%|          | 0.00/24.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c6c5627ac74234913aa660902ff9aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.jsonl:   0%|          | 0.00/4.43M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea6ddd8e8ce4461af293d4978650125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.jsonl:   0%|          | 0.00/8.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87d8e8e5c25a4931b1e700ab57b76f67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2783 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8611e1d2ac0473e98a1dfd3257008dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61b089cd307c4e8ab456a8f090d69e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57055e2f82ab4d46aa0209c761d0cc9d"}},"metadata":{}}]},{"cell_type":"code","source":"def generate_summary(input_text):\n    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    summary_ids = model.generate(inputs[\"input_ids\"].to(device), max_length=256, min_length=10, length_penalty=2.0, num_beams=4)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:13.282414Z","iopub.execute_input":"2024-11-19T20:53:13.282668Z","iopub.status.idle":"2024-11-19T20:53:13.287432Z","shell.execute_reply.started":"2024-11-19T20:53:13.282643Z","shell.execute_reply":"2024-11-19T20:53:13.286548Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data=answersumm['train']\ninp_dataset=[]\nout_dataset=[]\nfor sample in train_data:\n    ref_summ=sample['summaries'][0][1]\n    query=sample['question']['question']\n    inp_str=\"\"\n    for ans in sample['answers']:\n        for sent in ans['sents']:\n            inp_str+=\" \"+sent['text']\n    inp_dataset.append(inp_str)\n    out_dataset.append(ref_summ)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T10:56:59.772118Z","iopub.execute_input":"2024-11-18T10:56:59.772410Z","iopub.status.idle":"2024-11-18T10:57:03.328526Z","shell.execute_reply.started":"2024-11-18T10:56:59.772380Z","shell.execute_reply":"2024-11-18T10:57:03.327714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SummarizationDataset(Dataset):\n    def __init__(self, texts, summaries, tokenizer, max_input_len=1024, max_target_len=512):\n        self.texts = texts\n        self.summaries = summaries\n        self.tokenizer = tokenizer\n        self.max_input_len = max_input_len\n        self.max_target_len = max_target_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        inputs = self.tokenizer(\n            self.texts[idx],\n            max_length=self.max_input_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        targets = self.tokenizer(\n            self.summaries[idx],\n            max_length=self.max_target_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n            \"labels\": targets[\"input_ids\"].squeeze(0),\n            \"ref_summ\": self.summaries[idx],\n        }","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:13.288620Z","iopub.execute_input":"2024-11-19T20:53:13.289005Z","iopub.status.idle":"2024-11-19T20:53:13.307014Z","shell.execute_reply.started":"2024-11-19T20:53:13.288968Z","shell.execute_reply":"2024-11-19T20:53:13.306238Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model_name = \"facebook/bart-large\"\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n# train_dataset=SummarizationDataset(inp_dataset, out_dataset, tokenizer)\n# train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n# optimizer = AdamW(model.parameters(), lr=5e-5)\n# epochs=5","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:13.308077Z","iopub.execute_input":"2024-11-19T20:53:13.308812Z","iopub.status.idle":"2024-11-19T20:53:22.253373Z","shell.execute_reply.started":"2024-11-19T20:53:13.308775Z","shell.execute_reply":"2024-11-19T20:53:22.252616Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42331f8c3454ff1b627f00d5fc319e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2439644b3147979ea4c6ed820d1070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0705b491bcac448e92ac264315777b09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b817d60ddc5d4a84b0c39d4c2819c70c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f4a6e1258dc43a39bb1644875a2fc89"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d78e363ec1804cb8bbcaa1e0e2fa21ff"}},"metadata":{}}]},{"cell_type":"code","source":"model.train()\nfor epoch in range(epochs):\n    epoch_loss = 0\n    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels,\n        )\n        loss = outputs.loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_dataloader)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T10:57:12.059113Z","iopub.execute_input":"2024-11-18T10:57:12.059910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'BART_FT2.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Epoch 1 Loss: 1.1762466367077211","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=torch.load('../input/bart-ft/BART_FT2.pth')","metadata":{"execution":{"iopub.status.busy":"2024-11-18T18:07:12.962667Z","iopub.execute_input":"2024-11-18T18:07:12.963013Z","iopub.status.idle":"2024-11-18T18:07:22.551279Z","shell.execute_reply.started":"2024-11-18T18:07:12.962985Z","shell.execute_reply":"2024-11-18T18:07:22.550504Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1732550558.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model=torch.load('../input/bart-ft/BART_FT2.pth')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data=answersumm['test']\ntest_inp_dataset=[]\ntest_out_dataset=[]\nfor sample in test_data:\n    ref_summ=sample['summaries'][0][1]\n    query=sample['question']['question']\n    inp_str=\"\"\n    for ans in sample['answers']:\n        for sent in ans['sents']:\n            inp_str+=\" \"+sent['text']\n    test_inp_dataset.append(\"Query: \"+query+\", Answers: \"+inp_str)\n    test_out_dataset.append(ref_summ)\n\ntest_dataset=SummarizationDataset(test_inp_dataset,test_out_dataset,tokenizer)\ntest_dataloader=DataLoader(test_dataset,batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:53:22.254335Z","iopub.execute_input":"2024-11-19T20:53:22.254568Z","iopub.status.idle":"2024-11-19T20:53:23.286361Z","shell.execute_reply.started":"2024-11-19T20:53:22.254541Z","shell.execute_reply":"2024-11-19T20:53:23.285386Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.eval()\nscores=[]\ngen_outputs=[]\ntrue_summ=[]\nfor batch in tqdm(test_dataloader):\n    with torch.no_grad():\n        output_ids = model.generate(\n            input_ids=batch[\"input_ids\"].to(device),\n            attention_mask=batch[\"attention_mask\"].to(device),\n            max_length=256,\n            num_beams=4,\n            early_stopping=True,\n        )\n    batch_outputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output_ids]\n    gen_outputs.extend(batch_outputs)\n    true_summ.extend(batch['ref_summ'])\nfor a,b in tqdm(zip(gen_outputs,true_summ)):\n    scores.append(compute_rouge_score(a,b))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-19T20:53:23.289019Z","iopub.execute_input":"2024-11-19T20:53:23.289319Z","iopub.status.idle":"2024-11-19T21:30:44.018002Z","shell.execute_reply.started":"2024-11-19T20:53:23.289287Z","shell.execute_reply":"2024-11-19T21:30:44.017064Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 250/250 [34:59<00:00,  8.40s/it]\n1000it [02:21,  7.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"arr=[]\nfor x in scores:\n    arr.append(x['rouge1'])\nnp.average(arr)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T21:30:44.019053Z","iopub.execute_input":"2024-11-19T21:30:44.019317Z","iopub.status.idle":"2024-11-19T21:30:44.025679Z","shell.execute_reply.started":"2024-11-19T21:30:44.019284Z","shell.execute_reply":"2024-11-19T21:30:44.024899Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.1634897895446116"},"metadata":{}}]},{"cell_type":"code","source":"arr=[]\nfor x in scores:\n    arr.append(x['rouge2'])\nnp.average(arr)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T21:30:44.026704Z","iopub.execute_input":"2024-11-19T21:30:44.026958Z","iopub.status.idle":"2024-11-19T21:30:44.038858Z","shell.execute_reply.started":"2024-11-19T21:30:44.026929Z","shell.execute_reply":"2024-11-19T21:30:44.037721Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.04794819936555481"},"metadata":{}}]},{"cell_type":"code","source":"arr=[]\nfor x in scores:\n    arr.append(x['rougeL'])\nnp.average(arr)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T21:30:44.040046Z","iopub.execute_input":"2024-11-19T21:30:44.040283Z","iopub.status.idle":"2024-11-19T21:30:44.050804Z","shell.execute_reply.started":"2024-11-19T21:30:44.040259Z","shell.execute_reply":"2024-11-19T21:30:44.049879Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.10268001975541376"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}